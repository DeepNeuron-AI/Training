{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gror2KGz0rT"
      },
      "source": [
        "# PLEASE READ BEFORE STARTING\n",
        "1. **Don't edit this file, make a copy first:**\n",
        "  * Click on File -> Save a copy in Drive\n",
        "\n",
        "2. Also do the following:\n",
        "  * Click on Runtime -> Change runtime type -> Make sure hardware accelerator is set to GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7R1gCAtxvbh"
      },
      "source": [
        "# FastAI Tutorial\n",
        "Neural networks can be used for a whole host of tasks.\n",
        "The most basic of these though is image classification.\n",
        "Hence, today we'll go through using supervised learning to predict an images class/label from the CIFAR-10 dataset.\n",
        "\n",
        "We'll be using a library called FastAI which is built ontop of PyTorch to abstract away all the nitty-gritty details.\n",
        "Instead we can focus on comparing, contrarsting and understanding the different concepts we are able to use (like pretraining).\n",
        "By the end of this you should be roughly familiar with all the major concepts and theory behind basic neural nets!\n",
        "\n",
        "There's a lot going on here, so let's get going!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Classification"
      ],
      "metadata": {
        "id": "nDj2AgEfVB1F"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GyVVCkCltvy"
      },
      "source": [
        "## Importing Libraries\n",
        "Before we dive into the image classification task for this workshop, it is important the relevant libraries.\n",
        "\n",
        "\n",
        "Note here that we're importing everything from fastai's vision package, which is useful here but not in practice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzeDl-JllrlT"
      },
      "source": [
        "!pip install fastai --upgrade --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdC8-DnKWYS7"
      },
      "source": [
        "from fastai.vision.all import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oISzwhy5r5P"
      },
      "source": [
        "# Dataset Setup\n",
        "The first step for anything data related is to read a dataset and split the data into seperate training and validation partitions.\n",
        "In this tutorial we will be using the CIFAR-10 dataset, which includes 60,000 images, each belonging to one of ten categories.\n",
        "The dataset was collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. More information on the dataset can be found here: https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "## Initialising the Data into a pipeline\n",
        "To start, we will download the CIFAR-10 dataset and extract all the images from it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "830MtputmzmJ"
      },
      "source": [
        "path = untar_data(URLs.CIFAR) # Downloads url and unzips to folder destination"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GohbK51G8bR"
      },
      "source": [
        "Next we will initialise an instance of the 'DataBlock' class from the FastAI library. Which is a generic container that allows us to build a \"smart\" dataset called a dataloader, that contains the images seperated into training and validation sets, with their class attached to them. The purpose of the dataloader is that it specified a pipeline in which the model will receive data.\n",
        "\n",
        "We use the function ImageDataLoaders() to establish the dataloader by passing the path to the dataset, and the proportion of the dataset we wish to dedicate to the validation set.\n",
        "\n",
        "The validation dataset provides a way to check whether we are actually learning how to classify images or just overfitting the data (i.e. the model has just memorised which image belongs to which class).\n",
        "To do this we can create a validation dataset which the model doesn't train with, but insntead is used to \"test\" how well it does \"out-of-sample\".\n",
        "\n",
        "In this case we've used 20% of CIFAR-10's 60,000 images for validation (but you can change this)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtnJSZFUG4Mz"
      },
      "source": [
        "data = ImageDataLoaders.from_folder(path=path, valid_pct=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J-ClqMdIcpn"
      },
      "source": [
        "## Validating the dataset\n",
        "Before we proceed, it is important to validate the data to ensure that we do not have an incomplete dataset, a dateset with incorrect preprocessing, and more importantly to understand the data we are working in before we begin training.\n",
        "\n",
        "We know that CIFAR-10 has 60,000 images, lets start by verifying that we correctly set 20% of the dataset to the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUEHSaDmB9jq"
      },
      "source": [
        "print(\"Training Set Size = \" + str(len(data.train_ds)))\n",
        "print(\"Validiation Set Size = \" + str(len(data.valid_ds)))\n",
        "print(\"Total Dataset Size = \" + str(len(data.train_ds) + len(data.valid_ds)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMqzc8zBQxp6"
      },
      "source": [
        "We can also validate the dataset by checking a random batch to view the images with their respective labels.\n",
        "\n",
        "Notice that the images are blurry, this is because the CIFAR dataset is used to train neural nets to identify far away objects that are often pixilated. The images have been taken while the camera setting was zoomed in to maximum.\n",
        "\n",
        "Hence, this image classification is a real life example of where AI can be applied."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agHpaXAHTidU"
      },
      "source": [
        "data.show_batch(figsize=(10,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUxBN2oIV0Bz"
      },
      "source": [
        "# Model Setup\n",
        "## Transfer Learning\n",
        "Transfer learning allows us to repurpose a model trained for one task to many others.\n",
        "This means our research and practical testing of image classification techniques using neural nets on CIFAR-10 can also be used for other datasets (and even other broad domains like Natural Language Processing).\n",
        "\n",
        "This is why transfer learning is one of the most fundemental aspect of deep learning.\n",
        "We can find several examples of this, including:\n",
        "- A model trained for the ImageNet competition can be repurposed to recognise between different dog breeds\n",
        "- A model trained on ImageNet can be repurposed to help us classify whether an image is a 'plane' or a 'dog'\n",
        "- A language model trained on Spanish could be adapted and repurposed for French/Italian\n",
        "\n",
        "The primary benefit of transfer learning is that we can use the same \"toolkit\" or \"basic techniques\" for a very wide variety of complex problems.\n",
        "Hence, we have solid foundations which we can build up upon.\n",
        "This cuts down on training time *substantially*.\n",
        "\n",
        "\n",
        "In this example we're using a pretrained *ResNet-34* (more advanced model) as our base architecture, then retraining it to adapt it to classify our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn9d0OJSCSf1"
      },
      "source": [
        "learn = cnn_learner(data, resnet34, metrics=accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nc2P_9DCWhDX"
      },
      "source": [
        "# Training\n",
        "## Determining the Learning Rate\n",
        "An important thing to figgure out is what learning rate to use.\n",
        "It's a hard problem to solve, but we can nudge ourselves in the right direction by finding out how changing our learning rate effects the loss initially.\n",
        "\n",
        "We see this with FastAI's `lr_find()`.\n",
        "It provides the minimum learning rate (divided by 10) and the point of steepest descent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70TmnJcbX7EK"
      },
      "source": [
        "learn.lr_find()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6FGnoo0YqLx"
      },
      "source": [
        "You can try and pick the best learning rate and put it into the training method below (in the next section) to see how it changes your results.\n",
        "If you try a few different values, you'll soon see that your choice greatly effects the results!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWSjg9LRZH1s"
      },
      "source": [
        "## Training Time!\n",
        "We are now ready to begin training!\n",
        "\n",
        "To start, we establish our base learning rate which we can choose from our previous graph. For this experiment, you will need to assign the variable `base_lr` with a learning rate of your choice.\n",
        "\n",
        "After selecting your learning rate, execute the code block below before you continue reading as it may take some time to train the model.\n",
        "\n",
        "After the learning rate is defined, we freeze the lower layers by calling the `freeze()` method. This concept is taken from Transfer Learning, as we have previously spoken about, and it will allow us to 'custom fit' the *ResNet-34* to the dataset, as the network is already pretrained on a similar problem. The actual 'freezing' occurs by preventing any weights in the lower layers from being modified until we unfreeze, allowing us to change the final fully connected layers.\n",
        "\n",
        "Now we can train our fully connected layers using the `fit_one_cycle()` method. This method takes in how many epochs we want to train and the learning rate at which we want to train our network at. We have also inputted an optional argument which is slightly out of scope for this workshop.\n",
        "\n",
        "After one epoch, we unfreeze the lower layers so that ALL layers can now have their weights updated according to the loss function. We can then train for another 3 epochs and evaluate the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjkBCV_8CxrO"
      },
      "source": [
        "base_lr = #<Replace with desired learning rate>\n",
        "learn.freeze()\n",
        "learn.fit_one_cycle(1, base_lr, pct_start=0.99)\n",
        "base_lr /= 2\n",
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(3, base_lr, pct_start=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH2PyEYkgZwa"
      },
      "source": [
        "While it is training, you may hopefully notice that the training loss and validation loss get lower over time, and the accuracy may increase as the model learns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiNSeJQNW7TC"
      },
      "source": [
        "## Saving Model Weights\n",
        "Once training has completed, we should save our models weights (so we can use or pretrain from it later).\n",
        "\n",
        "This could also allow:\n",
        "- Reverting to a previous model\n",
        "- Tracking a models progress through special version-control\n",
        "\n",
        "Model weights can be simply reloaded with `learner.load('some-name')`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl-nenHGW-4S"
      },
      "source": [
        "learn.save('trained-lr-default')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlQZlz1QjXNF"
      },
      "source": [
        "# Evaluation\n",
        "Once the training has been completed, we need to gauge how good/bad our model is.\n",
        "\n",
        "## Sample Predictions\n",
        "We can view some predictions with our newly trained model with the `show_results()` method. Activate the block below to see how it went!\n",
        "\n",
        "The text at the top indicates the actual class of the image, the bottom text indicates the predicted class, if they're green, our model successfully predicted correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xowfQ20h-H6"
      },
      "source": [
        "learn.show_results()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV94t__pjvM9"
      },
      "source": [
        "Viewing a sample batch of predictions is visually appealing, however there are more appropriate metrics to validate the model.\n",
        "\n",
        "## Model Validation\n",
        "It is important to validate our models with appropriate metrics to determine how well the model is performing, and whether or not further investigation is required. Today we will be doing using a Confusion Matrix and viewing our top losses. We will start by creating an instance of the `ClassificationInterpretation` class from our model in order to begin."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Erc2_QflSQE"
      },
      "source": [
        "interp = ClassificationInterpretation.from_learner(learn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX90aRSwk4ra"
      },
      "source": [
        "### Confusion Matrix\n",
        "A Confusion Matrix can be used to determine where our model is producing false positives or false negatives. Click below to see what happened!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrtX8zCUjnKh"
      },
      "source": [
        "interp.plot_confusion_matrix()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbcCG7-xlim1"
      },
      "source": [
        "### Top Losses\n",
        "We can also produce a set of images that fastai considers 'top losses' with the `plot_top_losses()` method. The images are considered 'top losses' based on the probability that the prediction was correct. The images with a probability of 1 technically don't have a probability of 1, it's an softmax bug within FastAI."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okqooChcmgkH"
      },
      "source": [
        "interp.plot_top_losses(8, figsize=(15,11))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMeA5AForEKk"
      },
      "source": [
        "So how did your model perform? Did it increase in accuracy over time? Maybe have a play around with the base learning rate a little more and see what you can come up with. Maybe try thinking about using the lowest point on the learning rate curve or the point of steepest descent and compare the results.\n",
        "\n",
        "## Group Evaluation\n",
        "As a breakout room, discuss how your models performed.\n",
        "Try and consider areas you believed they performed well in, along with where you think they could improve.\n",
        "Think about why there may be some common classes where confusion occurs between the actual and predicted classes while you wait for the results of your new training.\n",
        "Feel free to additionally discuss the effect of learning rates once again."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Segmentation\n",
        "Segmentation is a problem where we have to predict a category for each pixel of the image and segment parts of the image based on respective categories. For this task, we will use the [Camvid](https://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/) dataset, a dataset of screenshots from cameras in cars. Each pixel of the image has a label such as \"road\", \"car\" or \"pedestrian\"."
      ],
      "metadata": {
        "id": "4lakdZRaQ2AI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = untar_data(URLs.CAMVID_TINY) # Downloads url and unzips to folder destination\n",
        "path.ls()"
      ],
      "metadata": {
        "id": "ZTd1me3ERMK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The images folder contains the images, and the corresponding segmentation masks of labels are in the labels folder. The codes file contains the corresponding integer to class (the masks have an int value for each pixel)."
      ],
      "metadata": {
        "id": "WEpjR5GJSBtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "codes = np.loadtxt(path/'codes.txt', dtype=str)\n",
        "codes"
      ],
      "metadata": {
        "id": "JjJJG4w7SCWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The get_image_files function is an in-built function from FastAI that helps us grab all the image filenames:"
      ],
      "metadata": {
        "id": "sMB2q93lS4Rl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fnames = get_image_files(path/\"images\")\n",
        "fnames[0]"
      ],
      "metadata": {
        "id": "SG-6kukKS85q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's have a look in the labels folder:"
      ],
      "metadata": {
        "id": "KJmNTKJNTRdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(path/\"labels\").ls()[0]"
      ],
      "metadata": {
        "id": "22aSwXckTWpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems the segmentation masks have the same base names as the images but with an extra _P, so we can define a label function:"
      ],
      "metadata": {
        "id": "04pq4WdvTcva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def label_func(fn): return path/\"labels\"/f\"{fn.stem}_P{fn.suffix}\""
      ],
      "metadata": {
        "id": "DnHz_VA2ThMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then gather our data using SegmentationDataLoaders from FastAI:"
      ],
      "metadata": {
        "id": "def1i0ABTkiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dls = SegmentationDataLoaders.from_label_func(\n",
        "    path, bs=8, fnames = fnames, label_func = label_func, codes = codes\n",
        ")"
      ],
      "metadata": {
        "id": "Pid1wQ1MTrEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We do not need to pass item_tfms to resize our images here because they already are all of the same size.\n",
        "\n",
        "As usual, we can have a look at our data with the show_batch method. In this instance, the fastai library is superimposing the masks with one specific color per pixel:\n"
      ],
      "metadata": {
        "id": "f-d9dlbRTucP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dls.show_batch(max_n=6)"
      ],
      "metadata": {
        "id": "c-GcDYOjTySI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "A traditional CNN won't work for segmentation, we have to use a special kind of model called a UNet, so we use unet_learner to define our Learner:\n"
      ],
      "metadata": {
        "id": "z2Gms_cvT2rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = unet_learner(dls, resnet34)\n",
        "learn.fine_tune(6)"
      ],
      "metadata": {
        "id": "BifcqVMIT50D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use show_results to get target vs prediction within the image itself"
      ],
      "metadata": {
        "id": "oPo9n7TGT9ja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn.show_results(max_n=4, figsize=(10,8))"
      ],
      "metadata": {
        "id": "q2r1113xUI60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "We can also sort the model's errors on the validation set using the SegmentationInterpretation class and then plot the instances with the k highest contributions to the validation loss.\n"
      ],
      "metadata": {
        "id": "rvS46DtSUOm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interp = SegmentationInterpretation.from_learner(learn)\n",
        "interp.plot_top_losses(k=3)"
      ],
      "metadata": {
        "id": "R2GibRihUQqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Group Evaluation\n",
        "As a breakout room, discuss how segmentation can be useful along with why do we need them in the first place.\n",
        "Feel free to discuss this with other members too."
      ],
      "metadata": {
        "id": "YzFWyq2I4YUs"
      }
    }
  ]
}