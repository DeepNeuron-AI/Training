{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3_PyTorch_Introduction_Tutorial.ipynb","provenance":[{"file_id":"https://github.com/DeepNeuron-AI/Training/blob/master/Workshops/Workshop%202%20-%20Intro%20to%20PyTorch/Classical%20PyTorch%20Tutorial","timestamp":1646450169077},{"file_id":"1Am-T7CPrf3CAPlfryTZ9bLMclh6jj8dB","timestamp":1607398496737}],"collapsed_sections":["pGTnInyEharX","uPphsYC4F5ey","zeBcbizYHwXK","8MeMOg7JzLDc","tO0pAo_RM673","QBxZBs-qvIVv","TVXfDWzFP7s8","VbjmPAZRsNh1","wyOsdHe6QvE-","pBqDIyqi-YND","XamfizJT-Y_s","E-4Og-mnVnnV"],"toc_visible":true,"private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"pGTnInyEharX"},"source":["# Before you start\n","1. **Don't edit this file, make a copy first:**\n","  * Click on File -> Save a copy in Drive\n","\n","2. Also do the following:\n","  * Click on Runtime -> Change runtime type -> Make sure hardware accelerator is set to GPU\n","\n","3. I recommend going through this notebook TWICE. The first time, just try and get a feel for the overall structure of the code, and how it's similar to FastAI. The second time, try unhiding the functions to get a feel for how pytorch is different to FastAI."]},{"cell_type":"markdown","source":["# Introduction to PyTorch\n","\n","This workshop is going to be a runthrough of creating a deep learning system with PyTorch.\n","\n","I've tried to simplify things as much as possible, wrapping the code into functions. The code should hopefully feel similar to the FastAI code from last week.\n","\n","I've hidden the code for the functions so you can get a feel for how the whole system works and how it compares to the FastAI approach, but once you get a feel for the structure of the code, I really recommend trying to open up the hidden functions and go through them with your demonstrator to see how pytorch works.\n","\n","You should find the notebook is structured as follows:\n","1. Create the dataset\n","2. Creating a model\n","3. Training and testing the model\n","4. Evaluate the model\n"],"metadata":{"id":"uPphsYC4F5ey"}},{"cell_type":"markdown","source":["# Library Imports\n","PyTorch is called \"torch\" when importing"],"metadata":{"id":"OOtijSHnHf3e"}},{"cell_type":"code","source":["import torch\n","from torch import nn\n","from torch import optim\n","from torchvision import datasets, models\n","from torchvision import transforms as T\n","import torchvision.transforms.functional as F\n","import torch.backends.cudnn as cudnn\n","\n","import matplotlib.pyplot as plt\n","import sklearn.metrics as skMet\n","import numpy as np\n","from tqdm.notebook import tqdm"],"metadata":{"id":"uXFcjBcIHnU_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataset functions\n","(Open up to see what the dataset function contains)"],"metadata":{"id":"zeBcbizYHwXK"}},{"cell_type":"markdown","source":["## create_dataset()\n","\n","First we put our transforms into a form to be used by PyTorch by composing them with `.Compose()`. Note that we only apply our defined transforms to the train data, as the goal is just to make the model generalize better, so we don't need to use them on the test set. We also do these 2 other transforms on both sets, `.ToTensor()` and `.Normalize()`. These help prep the data for the model. Feel free to ask your demos if you want the details!\n","\n","Next we create a *dataset*. This is basically an object that tells us *where* our data is located and can load *individual* images.\n","\n","Finally we create a *dataloader*. This is an object that can load *batches* (sets) of data. "],"metadata":{"id":"8MeMOg7JzLDc"}},{"cell_type":"code","source":["def create_dataset(dataset, transforms, batch_size):\n","    # Define transforms for the train and test set\n","    train_transforms = T.Compose(transforms + \n","                                [T.ToTensor(),\n","                                 T.Normalize([0.485, 0.456, 0.406], \n","                                             [0.229, 0.224, 0.225])])\n","\n","    test_transforms = T.Compose([T.ToTensor(),\n","                                 T.Normalize([0.485, 0.456, 0.406], \n","                                             [0.229, 0.224, 0.225])])\n","\n","    # Create dataset\n","    if dataset == \"CIFAR10\":\n","        train_dataset = datasets.CIFAR10('data/train', train=True, transform=train_transforms, download=True)\n","        test_dataset = datasets.CIFAR10('data/test', train=False, transform=test_transforms, download=True)\n","\n","    # Create dataloaders\n","    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","    return train_dataset, test_dataset, train_loader, test_loader"],"metadata":{"id":"G4q5xHVwzLV3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataset\n","Last time to create our dataset with FastAI, we used the follwing code:\n","\n","\n","```\n","data_bunch = (\n","    fastai.vision.ImageList.from_folder(path=Path('hotdog-not-hotdog-dataset'))\n","    .random_split_by_pct()\n","    .label_from_folder()\n","    .transform(size=224)\n","    .databunch()\n",")\n","```\n","\n","We get the data with `fastai.vision.ImageList.from_folder(path)`, split into train and test with `random_split_by_pct()`, get labels with `label_from_folder()`, transform (resize) our data with `transform(size=224)` and get our data into the proper format with `databunch()`.\n","<br></br>\n","\n","---\n","\n","<br> \n","With PyTorch, we need a few things. We could make our own dataset if we want, but thats a bit complicated. Instead, we can use some datasets provbided by pytorch for us for now. We're going to use CIFAR10 for now, which we'll look into soon. \n","\n","We also need to tell it what transforms to do. Here we're just going to do a random flip and a random rotation.\n","\n","Finally, we're going to tell the dataset how many images to pass at once to the model (This is called the batch size). This is a bit more abstract but can change how the model performs (feel free to try change this number to see what effects it has).\n","</br>"],"metadata":{"id":"CGSHG_UfIHj5"}},{"cell_type":"code","source":["transforms = [\n","    T.RandomRotation(30),\n","    T.RandomHorizontalFlip()\n","]\n","\n","dataset = \"CIFAR10\"\n","\n","train_dataset, test_dataset, train_loader, test_loader = create_dataset(\n","    dataset = dataset, transforms = transforms, batch_size = 32)"],"metadata":{"id":"Ez91fRqqK4AC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Dataset exploration\n","\n","Here, we visualize the data and some of it's properties to get a better idea of what our dataset consists of. \n","\n","Its also good to do this as it can help you ensure all your dataset code and transforms have worked correctly."],"metadata":{"id":"jVKmQq_UM2k2"}},{"cell_type":"markdown","source":["This shows what the 10 classes are:"],"metadata":{"id":"e1jjcJgcF5sH"}},{"cell_type":"code","source":["train_dataset.classes"],"metadata":{"id":"z0xMaJsCGCQP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here we visualize a sample of the images that make up the dataset:"],"metadata":{"id":"QQV5gNw1GL-F"}},{"cell_type":"code","source":["inputs, labels = next(iter(train_loader))\n","\n","# Fix image scaling (ask demos if you want the details)\n","inv_norm = T.Normalize(\n","    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n","    std=[1/0.229, 1/0.224, 1/0.255])\n","inputs = inv_norm(inputs)\n","\n","for im, label in zip(inputs, labels):\n","    plt.imshow(im.permute(1, 2, 0))\n","    plt.title(train_dataset.classes[label])\n","    plt.show()"],"metadata":{"id":"yoYx9GPjGMQz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Notice that the images are really blurry. This is because CIFAR10 is meant to be a dataset of small images. You should still be able to make out what each of the images are though, but hopefully this puts into context where the model could make mistakes.\n","\n","Also, you can see that some of the images are also rotated from the transform we applied."],"metadata":{"id":"tOZ9gxFoJnVq"}},{"cell_type":"markdown","source":["# Model functions\n","(Open up to see what the model function contains)"],"metadata":{"id":"tO0pAo_RM673"}},{"cell_type":"markdown","source":["## create_model()\n","\n","Here we do 2 main things. The first is this step where we set `param.requires_grad = True` for all the parameters in the model. What this is doing is telling the model to update ALL the weights (parameters = weights) in the model. We might only want to update some of the weights in the model, in which case we could tell the model to only update the weights we want.\n","\n","The second change we make is changing the size of the final layer. The models we use are often designed for ImageNet, which has 1000 different classes to predict. CIFAR10 only has 10 classes however, so we need to change the final layer to match this."],"metadata":{"id":"QBxZBs-qvIVv"}},{"cell_type":"code","source":["def create_model(model_type, dataset):\n","    model = model_type\n","\n","    # Set all weight to be updated\n","    for param in model.parameters():\n","        param.requires_grad = True\n","\n","    # Change size of final layer\n","    if dataset == \"CIFAR10\":\n","        out_ftrs = model.fc.in_features\n","        model.fc = nn.Linear(out_ftrs, 10)\n","\n","    return model"],"metadata":{"id":"kxQPR7aGvOBl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model\n","\n","Now we need to create our model. in FastAi, we did this by calling: \n","\n","```\n","learner = fastai.vision.cnn_learner(\n","    data=data_bunch, \n","    base_arch=fastai.vision.models.resnet50,\n","    pretrained=True, \n","    metrics=fastai.vision.accuracy # this is a function which computes accuracy\n",")\n","```\n","\n","In this code, we're creating a CNN (a more complex model type that handles images well) with `fastai.vision.cnn_learner()`. This model needs `data_bunch` to make sure the model is properly sized to work with the dataset. The model is goung to have the same structure as a famous model resnet50, be pretrained, and we care about the accuracy of the model.\n","<br></br>\n","\n","---\n","\n","<br> \n","In PyTorch, we need everything but accuracy. This is because we're going to have to manually compute the accuracy ourselves later, we can't just tell the model to automatically record it."],"metadata":{"id":"_r0MeJl-NBlw"}},{"cell_type":"code","source":["model = create_model(model_type = models.resnet50(pretrained=True), dataset = dataset)"],"metadata":{"id":"RLDDxJeANyeT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# GPU functions\n","(Open up to see what the GPU initialization function contains)"],"metadata":{"id":"TVXfDWzFP7s8"}},{"cell_type":"markdown","source":["## setup_GPU()\n","\n","This is pretty straigntforward, just a couple of lines to make sure the GPU will be properly optimized, along with checking the GPU is actually available.\n","\n","We also call `.to(device)` here, which is how we tell pytorch what our model should run on. If there is a GPU available, the device should be `cuda:0`, otherwise it will be the `cpu`."],"metadata":{"id":"VbjmPAZRsNh1"}},{"cell_type":"code","source":["%%capture\n","def setup_GPU():\n","    torch.cuda.empty_cache()\n","    cudnn.benchmark = True  # Optimise for hardware\n","\n","    # Check that the GPU is available\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","    #Make sure model uses the GPU\n","    model.to(device)\n","\n","    return device"],"metadata":{"id":"1aKhvPKmsYeG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Initialize GPU\n","In PyTorch we need to explicitly write code to use the GPU, so we need to first setup the GPU. If there isn't a GPU that can be used, `device` will instead just be set to CPU (and the model will train slower)."],"metadata":{"id":"ZR-iOg9YP4U5"}},{"cell_type":"code","source":["device = setup_GPU()"],"metadata":{"id":"136Jz2qZQTH0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train/Test functions \n","(Open up to see what the train/test functions contain)"],"metadata":{"id":"wyOsdHe6QvE-"}},{"cell_type":"markdown","source":["## train()\n","\n","Okay, this is going to be the most complicated part of our PyTorch system, but if we break it down, you'll find that it's actually quite straightforward.\n","\n","1. We loop over all of the data using `for i, (inputs, labels) in enumerate(train_loader, 0):`.\n","2. We make sure the data is on the GPU so it can be used by the model with `inputs, labels = inputs.to(device), labels.to(device)`. This is similar to `model.to(device)` if you saw this earlier.\n","3. Reset the optimizer with `optimizer.zero_grad()`.\n","4. Pass the inputs through the model with `outputs = model(inputs)`.\n","5. Compute the loss with `loss = loss_fn(outputs, labels)`.\n","6. Do gradient descent with `loss.backward()` and `optimizer.step()`\n","\n","You can see the the fundamental process here, cutting all the pytorch specific fluff is:\n","\n","> Pass data through model -> Compute the loss -> Update the model's weights\n","\n","\n","For all the data in the dataset.\n","\n","And that's all there is to it! The only other thing we do is also make sure to track our loss by keeping a running total."],"metadata":{"id":"pBqDIyqi-YND"}},{"cell_type":"code","source":["def train(model, train_loader, loss_fn, optimizer, device):\n","    model.train() # puts the model in training mode\n","    running_loss = 0\n","    with tqdm(total=len(train_loader)) as pbar: # Creates progress bar, can ignore\n","        for i, (inputs, labels) in enumerate(train_loader, 0): # loops through training data\n","            inputs, labels = inputs.to(device), labels.to(device) # puts the data on the GPU\n","\n","            # forward + backward + optimize                                          \n","            optimizer.zero_grad() # clear the gradients in model parameters\n","            outputs = model(inputs) # forward pass and get predictions\n","            loss = loss_fn(outputs, labels) # calculate loss\n","            loss.backward() # calculates gradient w.r.t to loss for all parameters in model that have requires_grad=True\n","            optimizer.step() # iterate over all parameters in the model with requires_grad=True and update their weights.\n","\n","            running_loss += loss.item() # sum total loss in current epoch for print later\n","\n","            pbar.update(1) #increment our progress bar\n","\n","    return running_loss/len(train_loader) # returns the total training loss for the epoch"],"metadata":{"id":"tfbTOC_h-Yfh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## test()\n","\n","The test function is very similar to the train function, so if you can understand that, you can understand this too. I'll run through the changes here:\n","\n","1. Tell the model to not bother storing gradients (what we need for weight updates) with `with torch.no_grad():`.\n","2. We don't want to update the model, so we don't perform gradient descent. This means we don't need to run `loss.backward()` and `optimizer.step()` here.\n","\n","We also want to track the accuracy, so we have some code to do that too.\n","1. Take the highest probability class as the prediction by the model. We do this by just taking the index of the max output with `_, predicted = torch.max(outputs, 1)`.\n","2. Track the number of correct predictions with `correct += (predicted == labels).sum().item()`.\n","3. Track the total number of predictions with `total += labels.size(0)`.\n","\n","At the end we can get the accuracy by dividing the two (`correct/total`). "],"metadata":{"id":"XamfizJT-Y_s"}},{"cell_type":"code","source":["def test(model, test_loader, loss_fn, device):\n","    model.eval() # puts the model in test mode\n","    running_loss = 0\n","    total = 0\n","    correct = 0\n","    \n","    with torch.no_grad(): # save memory by not saving gradients which we don't need \n","        with tqdm(total=len(test_loader)) as pbar:\n","            for images, labels in iter(test_loader):\n","                images, labels = images.to(device), labels.to(device) # put the data on the GPU\n","                outputs = model(images) # passes image to the model, and gets a ouput which is the class probability prediction\n","\n","                test_loss = loss_fn(outputs, labels) # calculates test_loss from model predictions and true labels\n","                running_loss += test_loss.item()\n","\n","                _, predicted = torch.max(outputs, 1) # turns class probability predictions to class labels\n","                correct += (predicted == labels).sum().item() # sums the number of correct predictions\n","                total += labels.size(0) # sums the number of predictions\n","                \n","        \n","                pbar.update(1)\n","\n","        return running_loss/len(test_loader), correct/total # return loss value, accuracy"],"metadata":{"id":"NNfV8j-V-ZU1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training and testing \n","\n","To train the model in FastAI, it was a really simple, one line call:\n","```\n","learner.fit_one_cycle(cyc_len=5, max_lr=1e-4)\n","```\n","This would train our model for 5 epochs with a learning rate of 1e-4.\n","<br></br>\n","\n","---\n","<br> \n","Things are a bit more complicated in PyTorch. We need to define a lot more things ourself, but this also give us a lot more power and choice over the training.\n","\n","First we have to define what our loss function is going to be. This is the actual mathematical function that tells the model how right/wrong it is, and what we want to minimize.\n","\n","Next, we define our optimizer. This is basically what performs gradient descent and updates the weights of our model. Just know that there are a few different strategies for the best way to update the weights, and here we use 'Adam'. As the optimizer is updating the weights, it also needs the learning rate.\n","\n","Finally, we want to train and test for a specific number of epochs. We do this by looping over a train and test function. These functions are where all the magic really happens, and I really recommend trying to dive into how these functions actually work (Don't be shy to get your demonstrator to help you walk through them!).\n","\n","The only other thing we're doing here is storing all the losses and accuracies so we can plot them later."],"metadata":{"id":"0fWRWCuOQ7nS"}},{"cell_type":"code","source":["# Loss functions\n","loss_fn = nn.CrossEntropyLoss()\n","\n","# Optimizer that performs gradient descent\n","optimizer = optim.Adam(model.parameters(), lr=1e-4)\n","\n","train_loss_list = []\n","test_loss_list = []\n","acc_list = []"],"metadata":{"id":"KBG8W_ARjDeo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Note that if you want, you can rerun the below code block to train your model more without restarting"],"metadata":{"id":"N03jeCzwjIOH"}},{"cell_type":"code","source":["# Train and test loop\n","total_epoch = 10\n","\n","for epoch in range(total_epoch): # loops through number of epochs\n","  train_loss = train(model, train_loader, loss_fn, optimizer, device) \n","  test_loss, accuracy = test(model, test_loader, loss_fn, device) \n","  print(\"Epoch: {}/{}, Training Loss: {}, Test Loss: {}, Test Accuracy: {}\".format(\n","      epoch+1, total_epoch, train_loss, test_loss, accuracy))\n","  print('-' * 20)\n","\n","  train_loss_list.append(train_loss)\n","  test_loss_list.append(test_loss)\n","  acc_list.append(accuracy)\n","\n","print(\"Finished Training\")\n","\n","#Save the model after we're done\n","torch.save(model.state_dict(), 'trained_model')"],"metadata":{"id":"ys-1ycZfTmwi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluation functions\n","(Open up to see what the evaluation functions contain)"],"metadata":{"id":"E-4Og-mnVnnV"}},{"cell_type":"markdown","source":["## Plot functions\n","\n","For this we use matplotlib. Most of the functions here should be pretty self-explanatory, its really all just setting attributes of the plot."],"metadata":{"id":"V2wb9_fiuu_9"}},{"cell_type":"code","source":["def plot_losses(train_loss, test_loss):\n","    plt.plot(train_loss, label='Train')\n","    plt.plot(test_loss, label='Test')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.title('Model losses')\n","    plt.show()"],"metadata":{"id":"HpNC3AMdvGGS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_accuracy(test_accuracy):\n","    plt.plot(test_accuracy)\n","    plt.grid(True)\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Accuracy (%)')\n","    plt.title('Model accuracy')\n","    plt.show()"],"metadata":{"id":"QGiJ1vJyvund"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Confusion matrix value generator\n","\n","To make the confusion matrix, we need the true labels and predicted labels of every datapoint in 2 lists. To make these lists we're going to basically do a test loop, but instead of computing loss and accuracy we're going to store the labels and model predictions into 2 lists `true_label` and `pred_label`."],"metadata":{"id":"h_gMzPs41S5l"}},{"cell_type":"code","source":["def getConfMatValues(model, loader, device):\n","    model.eval() \n","\n","    true_label = np.array([])\n","    pred_label = np.array([])\n","    with torch.no_grad():\n","        with tqdm(total=len(loader)) as pbar:\n","            # loops through training data\n","            for inputs, labels in loader:\n","                # Store true labels\n","                true_label = np.append(true_label, labels.flatten().int().numpy())\n","\n","                inputs, labels = inputs.to(device), labels.to(device)  \n","                outputs = model(inputs)\n","\n","                # store predictions\n","                _, predicted = torch.max(outputs, 1)\n","                pred_label = np.append(pred_label, predicted.to('cpu').flatten().int().numpy())\n","\n","                pbar.update(1)\n","\n","    return true_label, pred_label"],"metadata":{"id":"VyCJhF1a1Xls"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Top losses\n","\n","(I'm gonna be honest, this is a bit of a monstrosity. This is something I had to whip up really quickly for an assignment and it shows. If you ever want to do this yourself I would really recommend looking up a better way of doing this yourself. - Jason) \n","\n","The quick summary is that this is basically the test loop we've already seen, but it also keeps an ordered list with the top n worst predictions by the model. It does this by adding a new value to the list when the model both predicts the class incorrectly and the prediction probability is higher than a value in the list. The value goes to the correct position so that the probabilities are in descending order. Finally, the last value in the list is removed if the length of the list is above n."],"metadata":{"id":"CvVxp0Fp6UpS"}},{"cell_type":"code","source":["def top_n_errors(model, device, loader, n):\n","    model.eval()\n","    \n","    top_class_ims = [0.]\n","    top_class_pr = [0.]\n","    labels = [0.]\n","    ground_truth = [0.]\n","    \n","    with torch.no_grad():\n","        for batch_idx, (data, target) in enumerate(loader):\n","            target = target.type(torch.LongTensor)\n","            outputs = model(data.to(device))\n","            \n","            for i, out in enumerate(outputs):\n","                pr_vec = torch.nn.functional.softmax(out)\n","\n","                prediction_pr, prediction = torch.max(pr_vec, 0, keepdim=True)\n","                prediction_pr = prediction_pr.item()\n","                \n","                if prediction != target[i].to(device):\n","                    if prediction_pr > top_class_pr[-1]:\n","                        for j, pr in enumerate(top_class_pr):\n","                            if prediction_pr > pr:\n","                                top_class_pr.insert(j, prediction_pr)\n","                                top_class_ims.insert(j, inv_norm(data[i]).permute(1, 2, 0))\n","                                labels.insert(j, prediction)\n","                                ground_truth.insert(j, target[i].to(device))\n","                                break\n","                \n","                if len(top_class_pr) > n:\n","                    top_class_pr.pop()\n","                    top_class_ims.pop()\n","                    labels.pop()\n","                    ground_truth.pop()\n","                    \n","        return top_class_ims, labels, top_class_pr, ground_truth"],"metadata":{"id":"9dSZLVjz6sDi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluation\n","\n","Finally, we want to know how well our model has really done!\n"],"metadata":{"id":"nKlHlWqLVvjI"}},{"cell_type":"markdown","source":["## Plotting\n","\n","We can get a rough idea of the loss and accuracy of the model from the info we printed above, but just printing a bunch of numbers doesn't really make any trends in our loss/accuracy too clear. A better way would be to plot them.\n","\n","Here we have one plot with training and testing loss and another plot with test accuracy. Its good to have train and test on the same plot, as then you can check for overfitting. You'll know this is happening because the the loss will be increasing while the train loss will be decreasing."],"metadata":{"id":"Yu6nNXPGldhq"}},{"cell_type":"code","source":["plot_losses(train_loss = train_loss_list, test_loss = test_loss_list)\n","print('')\n","plot_accuracy(test_accuracy = acc_list)"],"metadata":{"id":"LL62X_zoovWH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Confusion matrix\n","\n","For image classification tasks, especially one without too many classes like this, it can be helpful to see exactly where the model is getting things wrong. This is where the confusion matrix can help. It tells us what the model predicts vs what the actual class is, letting us pinpoint where the model is making it's mistakes.\n","\n","FastAI can deal with the confusion matrix for us really nicely. All we need to do is call: \n","```\n","interp = ClassificationInterpretation.from_learner(learn)\n","interp.plot_confusion_matrix()\n","```\n","\n","Because pytorch is less self-contained than FastAI, we need to do a bit more to plot our confusion matrix. We can still use a package like scikit learn to make the plotting easier, but we now need to get the model's predictions ourselves."],"metadata":{"id":"KKLbvkWDxWRY"}},{"cell_type":"code","source":["true_label, pred_label = getConfMatValues(model, test_loader, device)\n","\n","skMet.ConfusionMatrixDisplay.from_predictions(true_label, \n","                                              pred_label, \n","                                              display_labels = train_dataset.classes, \n","                                              xticks_rotation = 'vertical')"],"metadata":{"id":"H0usXm2Sy8zl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Top Losses\n","\n","Another interesting way to visualize where the model went wrong is to plot the datapoints that gave the highest loss. These are basically the images the the image was the most confident in, but was wrong. Here we'll take the 5 most wrong images.\n","\n","Again, in FastAI we can just call a function:\n","```\n","interp = ClassificationInterpretation.from_learner(learn)\n","interp.plot_top_losses(5)\n","```\n","\n","But in pytorch things become more complicated. We need to write the code ourselves to find and plot the top losses."],"metadata":{"id":"BgSg3T2W5H1X"}},{"cell_type":"code","source":["top_class_ims, predicted_labels, top_class_pr, true_labels = top_n_errors(model, device, test_loader, 5)\n","\n","for i in range(5):\n","    plt.imshow(top_class_ims[i])\n","    plt.title('True class: %s \\nPredicted class: %s \\nProbability: %.8f'%(\n","        train_dataset.classes[true_labels[i]], train_dataset.classes[predicted_labels[i]], top_class_pr[i]))\n","    plt.show()\n","    print('')"],"metadata":{"id":"Ooned6BF94lH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# And that's it!\n","\n","You've now hopefully seen how the basic structure of deep learning in pytorch is exactly like in FastAI. \n","\n","If you haven't yet and feel up to it, I recommend going through this tutorial again and trying to unhide all the functions, to really engage what pytorch is all about and what makes it different to FastAI. This should give you a starting point for any deep learning project you feel like trying yourself.\n","<br></br>\n","If you want to go further on your own, the 2 main things you'll want to learn first are [how to create your own custom dataset](https://medium.com/analytics-vidhya/creating-a-custom-dataset-and-dataloader-in-pytorch-76f210a1df5d) and [how to create your own model](https://pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html).\n","\n","Also, check out [anaconda](https://www.anaconda.com/) and [weights and biases](https://wandb.ai/site), which make python package management and logging way easier.\n"],"metadata":{"id":"M0nK89RWAz2F"}}]}